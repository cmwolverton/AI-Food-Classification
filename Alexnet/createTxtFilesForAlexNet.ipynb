{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "## Place the data in Food-11 directory\n",
    "data_in_dir = os.path.join(cwd, \"Food-11\")\n",
    "assert(os.path.isdir(data_in_dir))\n",
    "\n",
    "subdirs = {\n",
    "    'train' : 'training',\n",
    "    'valid' : 'validation',\n",
    "    'eval'  : 'evaluation'}\n",
    "dirs = os.listdir(data_in_dir)\n",
    "\n",
    "## Validate we have these 3 subdirectories\n",
    "#assert(len(dirs) == len(subdirs) and sorted(dirs) == sorted(subdirs.values()))\n",
    "\n",
    "## Create output directory in current path to store images\n",
    "image_dir = os.path.join(cwd, \"food-classification-eda-images\")\n",
    "if not os.path.exists(image_dir): os.makedirs(image_dir)\n",
    "    \n",
    "## Create output directory to store the dataframes in pickle format\n",
    "pickle_dir = os.path.join(cwd, \"food-classification-pickle_data\")\n",
    "if not os.path.exists(pickle_dir): os.makedirs(pickle_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the images from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training, validation and evluation data directories\n",
    "training_data_dir = os.path.join(data_in_dir, subdirs['train'])\n",
    "validation_data_dir = os.path.join(data_in_dir, subdirs['valid'])\n",
    "evaluation_data_dir = os.path.join(data_in_dir, subdirs['eval'])\n",
    "\n",
    "## training, validation and evluation data images\n",
    "training_images = glob.glob(os.path.join(training_data_dir, \"*\"))\n",
    "validation_images = glob.glob(os.path.join(validation_data_dir, \"*\"))\n",
    "evaluation_images = glob.glob(os.path.join(evaluation_data_dir, \"*\"))\n",
    "\n",
    "all_images = [training_images, validation_images, evaluation_images]\n",
    "all_directories = [training_data_dir, validation_data_dir, evaluation_data_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'Bread',\n",
    " 1: 'Dairy product',\n",
    " 2: 'Dessert',\n",
    " 3: 'Egg',\n",
    " 4: 'Fried food',\n",
    " 5: 'Meat',\n",
    " 6: 'Noodles/Pasta',\n",
    " 7: 'Rice',\n",
    " 8: 'Seafood',\n",
    " 9: 'Soup',\n",
    " 10: 'Vegetable/Fruit',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9866\n",
      "C:\\Users\\WOLVCI10\\Desktop\\TensorFlow\\AI-Food-Classification\\Food-11\\training\\0_1.jpg\n",
      "0\n",
      "C:\\Users\\WOLVCI10\\Desktop\\TensorFlow\\AI-Food-Classification\\Food-11\\training\\0_1.jpg 0\n"
     ]
    }
   ],
   "source": [
    "training = pd.DataFrame(training_images)\n",
    "training.columns = ['Path']\n",
    "training['Label'] = training.Path.apply(lambda x: os.path.basename(x).split('_')[0])\n",
    "#training.describe()\n",
    "countDict = training.count()\n",
    "trainingCount = countDict['Path']\n",
    "print(trainingCount)\n",
    "\n",
    "print(training.Path[1])\n",
    "print(training.Label[1])\n",
    "myString = training.Path[1] + ' ' + training.Label[1]\n",
    "print(myString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a .txt file which contains path names and lables \n",
    "\n",
    "fid = open('.\\\\trainPathAndLabel.txt','w')\n",
    "\n",
    "for ix in range(trainingCount):\n",
    "    img_path  = training.Path[ix]\n",
    "    img_label = training.Label[ix] # get the radiograph category\n",
    "    pathLabelString = myString = training.Path[ix] + ' ' + training.Label[ix] + '\\n'\n",
    "\n",
    "    fid.write(pathLabelString)\n",
    "\n",
    "fid.close()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430\n"
     ]
    }
   ],
   "source": [
    "validation = pd.DataFrame(validation_images)\n",
    "\n",
    "validation.columns = ['Path']\n",
    "validation['Label'] = validation.Path.apply(lambda x: os.path.basename(x).split('_')[0])\n",
    "validation.describe()\n",
    "countDict = validation.count()\n",
    "validationCount = countDict['Path']\n",
    "print(validationCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a .txt file which contains path names and lables \n",
    "\n",
    "fid = open('.\\\\validationPathAndLabel.txt','w')\n",
    "\n",
    "for ix in range(validationCount):\n",
    "    img_path  = validation.Path[ix]\n",
    "    img_label = validation.Label[ix] # get the radiograph category\n",
    "    pathLabelString = myString = validation.Path[ix] + ' ' + validation.Label[ix] + '\\n'\n",
    "\n",
    "    fid.write(pathLabelString)\n",
    "\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3347\n"
     ]
    }
   ],
   "source": [
    "evaluation = pd.DataFrame(evaluation_images)\n",
    "\n",
    "evaluation.columns = ['Path']\n",
    "evaluation['Label'] = evaluation.Path.apply(lambda x: os.path.basename(x).split('_')[0])\n",
    "evaluation.describe()\n",
    "countDict = evaluation.count()\n",
    "evaluationCount = countDict['Path']\n",
    "print(evaluationCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a .txt file which contains path names and lables \n",
    "\n",
    "fid = open('.\\\\evaluationPathAndLabel.txt','w')\n",
    "\n",
    "for ix in range(evaluationCount):\n",
    "    img_path  = evaluation.Path[ix]\n",
    "    img_label = evaluation.Label[ix] # get the radiograph category\n",
    "    pathLabelString = myString = evaluation.Path[ix] + ' ' + evaluation.Label[ix] + '\\n'\n",
    "\n",
    "    fid.write(pathLabelString)\n",
    "\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
